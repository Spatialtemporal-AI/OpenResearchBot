# import h5py
# import json
# import numpy as np


# def print_tree(name, obj):
#     """æ‰“å°æ ‘çŠ¶ç»“æ„"""
#     indent = "  " * (name.count("/") - 1)
#     if isinstance(obj, h5py.Group):
#         print(f"{indent}ğŸ“‚ {name}/")
#     elif isinstance(obj, h5py.Dataset):
#         print(f"{indent}ğŸ“„ {name} (shape={obj.shape}, dtype={obj.dtype})")


# def h5_to_dict(obj):
#     """é€’å½’è½¬æ¢ HDF5 å¯¹è±¡ä¸º Python å­—å…¸"""
#     if isinstance(obj, h5py.Dataset):
#         data_info = {
#             "type": "dataset",
#             "shape": obj.shape,
#             "dtype": str(obj.dtype),
#         }
#         try:
#             # å°æ•°æ®é›†ç›´æ¥ä¿å­˜
#             if obj.size <= 100:
#                 data_info["data"] = obj[()].tolist()
#             else:
#                 # ä¿å­˜å‰10ä¸ªå…ƒç´ /æ ·æœ¬ä½œä¸ºé¢„è§ˆ
#                 if obj.ndim > 0:
#                     data_info["preview"] = obj[0 : min(10, obj.shape[0])].tolist()
#                 else:
#                     data_info["preview"] = obj[()].tolist()
#         except Exception as e:
#             data_info["error"] = str(e)
#         return data_info

#     elif isinstance(obj, h5py.Group):
#         group_info = {"type": "group", "items": {}}
#         for key, val in obj.attrs.items():
#             group_info[f"attr:{key}"] = (
#                 val.tolist() if isinstance(val, np.ndarray) else val
#             )
#         for key, item in obj.items():
#             group_info["items"][key] = h5_to_dict(item)
#         return group_info


# def read_h5_to_json(h5_path, json_path="output.json"):
#     with h5py.File(h5_path, "r") as f:
#         print(f"\n=== HDF5 æ–‡ä»¶æ ‘çŠ¶ç»“æ„: {h5_path} ===\n")
#         f.visititems(print_tree)

#         print("\n=== æ­£åœ¨å¯¼å‡ºä¸º JSON... ===")
#         structure = {"/": h5_to_dict(f)}

#     with open(json_path, "w", encoding="utf-8") as f:
#         json.dump(structure, f, ensure_ascii=False, indent=2)

#     print(f"\nâœ… å·²å°†å†…å®¹å†™å…¥ {json_path}")


# if __name__ == "__main__":
#     # ä¿®æ”¹ä¸ºä½ çš„ HDF5 æ–‡ä»¶è·¯å¾„
#     h5_file = "/mnt/data2/datasets/Real-robot/AgibotWorld-Alpha/Actiondata/proprio_stats/327/648642/proprio_stats.h5"
#     json_file = "output.json"
#     read_h5_to_json(h5_file, json_file)


import os
import json
import h5py
import cv2
import numpy as np
from typing import Dict, Any, List, Optional, Iterator
import imageio
import matplotlib.pyplot as plt
import pandas as pd


class RobotDatasetReader:
    def __init__(self, root_dir: str, xlsx: str, norm_stat_file: str, num_actions_chunk: int= 8):
        """
        root_dir: æ•°æ®é›†æ ¹ç›®å½•ï¼Œä¸‹é¢æœ‰ observations / parameters / proprio_stats / task_info
        """
        self.xlsx = xlsx
        self.root_dir = root_dir
        self.norm_stat_file = norm_stat_file
        with open(self.norm_stat_file, "r") as f:
            self.norm_stats = json.load(f)
        self.norm_stats = {k: {kk: np.array(v) for kk, v in vv.items()} for k, vv in self.norm_stats.items()}
        self.num_actions_chunk = num_actions_chunk
        self.observation_dir = os.path.join(root_dir, "observations")
        self.parameters_dir = os.path.join(root_dir, "parameters")
        self.proprio_dir = os.path.join(root_dir, "Actiondata/proprio_stats")
        self.task_info_dir = os.path.join(root_dir, "task_info")

        # ç¼“å­˜ task_info
        self.task_info = self._load_task_info()

    def _load_task_info(self) -> Dict[str, Any]:
        """è¯»å–æ‰€æœ‰ task_info json æ–‡ä»¶"""
        info = {}
        for fname in os.listdir(self.task_info_dir):
            if fname.endswith(".json"):
                set_id = fname.replace(".json", "").replace("task_", "")
                with open(os.path.join(self.task_info_dir, fname), "r") as f:
                    info[set_id] = json.load(f)
        self.frames = read_filtered_frame_ranges(self.xlsx,self.num_actions_chunk)
        return info

    def __iter__(self):
        for frame in self.frames:
            yield self.get_frame_data(frame["set_id"], frame["episode_id"], frame["frame_idx"])

    def __len__(self):
        return len(self.frames)

    def __getitem__(self, idx):
        return self.get_frame_data(self.frames[idx]["set_id"], self.frames[idx]["episode_id"], self.frames[idx]["frame_idx"])

    def get_episode_info(
        self, set_id: str, episode_id: int
    ) -> Optional[Dict[str, Any]]:
        """è·å–æŸä¸ª episode çš„ä»»åŠ¡æè¿°ä¿¡æ¯"""
        episodes = self.task_info.get(set_id, [])
        for e in episodes:
            if e["episode_id"] == episode_id:
                return e
        return None

    def get_action_for_frame(
        self, set_id: str, episode_id: int, frame_idx: int
    ) -> Optional[Dict[str, Any]]:
        """æ ¹æ®å¸§ç¼–å·æ‰¾åˆ°å½“å‰çš„ action é˜¶æ®µ"""
        ep_info = self.get_episode_info(set_id, episode_id)
        if ep_info is None:
            return None
        for action in ep_info["label_info"]["action_config"]:
            if action["start_frame"] <= frame_idx < action["end_frame"]:
                return action
        return None

    def _get_state(
        self, set_id: str, episode_id: int, frame_idx: int
    ) -> Dict[str, Any]:
        """
        è·å–æŸä¸€å¸§çš„ state çŠ¶æ€ï¼ˆåªè¯»å– state ä¸‹çš„æ•°æ®ï¼‰
        åŒ…å« joint / effector / end / head / robot / waist ç­‰å­æ¨¡å—
        """
        h5_path = os.path.join(
            self.proprio_dir, set_id, str(episode_id), "proprio_stats.h5"
        )
        state_data = {}
        if not os.path.exists(h5_path):
            raise FileNotFoundError(f"æœªæ‰¾åˆ°æ–‡ä»¶: {h5_path}")

        with h5py.File(h5_path, "r") as f:
            if "state" not in f:
                raise ValueError(f"æ–‡ä»¶ä¸­æ²¡æœ‰ state æ•°æ®: {h5_path}")

            # éå† state ä¸‹çš„æ‰€æœ‰ group
            for module_name in f["state"].keys():
                module_group = f["state"][module_name]
                module_data = {}

                for key in module_group.keys():
                    dataset = module_group[key]
                    if frame_idx < len(dataset):
                        module_data[key] = dataset[frame_idx]

                if module_data:
                    state_data[module_name] = module_data

            # timestamp å•ç‹¬å¤„ç†
            if "timestamp" in f and frame_idx < len(f["timestamp"]):
                state_data["timestamp"] = f["timestamp"][frame_idx]
        return state_data

    def get_frame_image(
        self, set_id: str, episode_id: int, frame_idx: int, camera: str = "head_color"
    ) -> np.ndarray:
        """
        ä»è§†é¢‘ä¸­æŠ½å–æŸä¸€å¸§å›¾åƒï¼ˆæ”¯æŒ AV1 è½¯ä»¶è§£ç ï¼Œä¸ä¿®æ”¹æºæ•°æ®é›†ï¼‰
        camera: è§†é¢‘æ–‡ä»¶åï¼ˆä¸å¸¦æ‰©å±•åï¼‰ï¼Œå¦‚ "head_color"ã€"head_left_fisheye_color"
        """
        video_path = os.path.join(
            self.observation_dir, set_id, str(episode_id), "videos", f"{camera}.mp4"
        )
        if not os.path.exists(video_path):
            return None

        try:
            # ä½¿ç”¨ imageio + ffmpeg è¯»å–è§†é¢‘å¸§
            import time
            st = time.time()
            reader = imageio.get_reader(video_path, format="ffmpeg")
            
            # total_frames = reader.count_frames()
            # print(f"è¯»å–è§†é¢‘å¸§æˆåŠŸ: {video_path}, frame_idx={frame_idx}, æ—¶é—´: {time.time() - st}")
            # if frame_idx >= total_frames:
            #     reader.close()
            #     return None
            
            frame = reader.get_data(frame_idx)
            reader.close()
            if frame.shape[2] == 4:  # å¦‚æœæœ‰ alpha é€šé“
                frame = frame[:, :, :3]
            return np.asarray(frame)

        except Exception as e:
            print(f"è¯»å–è§†é¢‘å¸§å¤±è´¥: {video_path}, frame_idx={frame_idx}, é”™è¯¯: {e}")
            return None

    def get_neighbor_frames(
        self,
        set_id: str,
        episode_id: int,
        frame_idx: int,
        window: int = 5,
        camera: str = "head_color",
    ) -> List[np.ndarray]:
        """è·å–å‰åå‡ å¸§å›¾åƒ"""
        imgs = []
        for i in range(frame_idx - window, frame_idx + window + 1):
            if i < 0:
                continue
            img = self.get_frame_image(set_id, episode_id, i, camera)
            if img is not None:
                imgs.append(img)
        return imgs

    def get_neighbor_frames_dict(
        self,
        set_id: str,
        episode_id: int,
        frame_idx: int,
        window: int = 5,
        camera: str = "head_color",
    ) -> dict:
        """
        è·å–å½“å‰å¸§å‰å window å¸§ï¼Œè¿”å›å­—å…¸å½¢å¼
        key: ç›¸å¯¹äºå½“å‰å¸§çš„åç§» (-window,...,-1,1,...,window)
        value: å¯¹åº”å¸§çš„ numpy å›¾åƒæ•°ç»„ï¼Œå¦‚æœè¶…å‡ºèŒƒå›´è¿”å› None
        """
        neighbor_frames = {}

        for i in range(1, window + 1):
            idx = frame_idx - i
            try:
                neighbor_frames[-i] = (
                    self.get_frame_image(set_id, episode_id, idx, camera)
                    if idx >= 0
                    else None
                )
            except Exception:
                neighbor_frames[-i] = None

        for i in range(1, window + 1):
            idx = frame_idx + i
            try:
                neighbor_frames[i] = self.get_frame_image(
                    set_id, episode_id, idx, camera
                )
            except Exception:
                neighbor_frames[i] = None

        return neighbor_frames

    def normalize_(self, value, norm_stat, quantize: bool = True):
        if quantize:
            value = (value - norm_stat['q01']) / (norm_stat['q99'] - norm_stat['q01'] + 1e-8)
        else:
            value = (value - norm_stat['mean']) / (norm_stat['std'] + 1e-8)
        return value

    def process_state(self, state, mode='states',quantize: bool = True):
        robot_state =[]
        effector = state['effector']
        end = state['end']
        robot_state.append(end['position'][0])
        robot_state.append(quaternion_to_rpy(end['orientation'][0]))
        robot_state.append(effector['position'][:1])
        robot_state.append(end['position'][1])
        robot_state.append(quaternion_to_rpy(end['orientation'][1]))
        robot_state.append(effector['position'][1:])
        robot_state = np.concatenate(robot_state)
        # assert robot_state.shape == (14,), f"robot_state shape: {robot_state.shape}, state: {state}"
        if robot_state.shape != (14,):
            robot_state = np.zeros(14)
        robot_state = self.normalize_(robot_state, self.norm_stats[mode], quantize)
        return robot_state

    def get_frame_data(
        self, set_id: str, episode_id: int, frame_idx: int, camera: str = "head_color"
    ) -> Dict[str, Any]:
        """
        é«˜å±‚å°è£…ï¼šè·å–æŸä¸€å¸§çš„å®Œæ•´ä¿¡æ¯
        - æ€»ä»»åŠ¡æè¿°
        - å½“å‰é˜¶æ®µä»»åŠ¡
        - state çŠ¶æ€
        - å›¾åƒæ•°æ®
        """
        ep_info = self.get_episode_info(set_id, episode_id)
        actions = []
        for i in range(frame_idx+1, frame_idx+self.num_actions_chunk+1):
            action = self._get_state(set_id, episode_id, i)
            action = self.process_state(action, mode='actions',quantize=True)
            actions.append(action)
        actions = np.array(actions)
        state = self._get_state(set_id, episode_id, frame_idx)
        state = self.process_state(state, mode='states',quantize=True)
        current_action = self.get_action_for_frame(set_id, episode_id, frame_idx)
        imgs = []
        imgs.append(self.get_frame_image(set_id, episode_id, frame_idx, 'head_color'))
        imgs.append(self.get_frame_image(set_id, episode_id, frame_idx, 'hand_left_color'))
        imgs.append(self.get_frame_image(set_id, episode_id, frame_idx, 'hand_right_color'))

        return {
            "episode_id": episode_id,
            "task_name": ep_info["task_name"] if ep_info else None,
            "init_scene_text": ep_info["init_scene_text"] if ep_info else None,
            'current_action': current_action['action_text'],
            "action": actions,
            "state": state,  # âœ… ç°åœ¨åŒ…å« joint/robot/effector/head ç­‰å®Œæ•´ state
            "image": imgs,
        }

    def get_frame_depth(
        self, set_id: str, episode_id: int, frame_idx: int, camera: str = "head_depth"
    ) -> Optional[np.ndarray]:
        """è·å–æŒ‡å®šå¸§çš„æ·±åº¦å›¾"""
        depth_dir = os.path.join(
            self.root_dir, "observations", str(set_id), str(episode_id), "depth"
        )
        depth_name = f"{camera}_{frame_idx:06d}.png"
        depth_path = os.path.join(depth_dir, depth_name)

        if not os.path.exists(depth_path):
            return None
        try:
            depth_img = cv2.imread(depth_path, cv2.IMREAD_UNCHANGED)
            return depth_img
        except Exception:
            return None

    def get_neighbor_depths(
        self,
        set_id: str,
        episode_id: int,
        frame_idx: int,
        window: int = 5,
        camera: str = "head_depth",
    ) -> Dict[int, np.ndarray]:
        """è·å–ç›¸é‚»å¸§çš„æ·±åº¦å›¾"""
        depth_dict = {}
        for offset in range(-window, window + 1):
            if offset == 0:
                continue
            neighbor_idx = frame_idx + offset
            if neighbor_idx < 0:
                continue
            depth_img = self.get_frame_depth(set_id, episode_id, neighbor_idx, camera)
            if depth_img is not None:
                depth_dict[offset] = depth_img
        return depth_dict


def quaternion_to_rpy(q, order: str = "xyzw", degrees: bool = False):
    """å°†å››å…ƒæ•°è½¬æ¢ä¸ºæ¬§æ‹‰è§’ RPY (roll, pitch, yaw)ã€‚

    é‡‡ç”¨èˆªç©ºå¸¸ç”¨çš„ ZYX (yaw-pitch-roll) ç»„åˆï¼Œå¯¹åº”è¿”å›é¡ºåºä¸º (roll, pitch, yaw)ã€‚

    å‚æ•°:
    - q: é•¿åº¦ä¸º4çš„åºåˆ—æˆ– numpy æ•°ç»„ã€‚
    - order: å››å…ƒæ•°åˆ†é‡é¡ºåºï¼Œ"wxyz" æˆ– "xyzw"ã€‚
    - degrees: True åˆ™è¿”å›è§’åº¦åˆ¶ï¼Œå¦åˆ™å¼§åº¦åˆ¶ã€‚
    """
    arr = np.asarray(q, dtype=np.float64)
    if arr.shape[-1] != 4:
        raise ValueError(f"å››å…ƒæ•°ç»´åº¦å¿…é¡»ä¸º4ï¼Œæ”¶åˆ°: shape={arr.shape}")

    if order.lower() == "wxyz":
        w, x, y, z = arr
    elif order.lower() == "xyzw":
        x, y, z, w = arr
    else:
        raise ValueError("order ä»…æ”¯æŒ 'wxyz' æˆ– 'xyzw'")

    # å½’ä¸€åŒ–ï¼Œé¿å…æ•°å€¼æ¼‚ç§»
    norm = np.sqrt(w*w + x*x + y*y + z*z)
    if norm == 0:
        raise ValueError("å››å…ƒæ•°èŒƒæ•°ä¸º0")
    w, x, y, z = w / norm, x / norm, y / norm, z / norm

    # roll (xè½´æ—‹è½¬)
    t0 = 2.0 * (w * x + y * z)
    t1 = 1.0 - 2.0 * (x * x + y * y)
    roll = np.arctan2(t0, t1)

    # pitch (yè½´æ—‹è½¬)
    t2 = 2.0 * (w * y - z * x)
    t2 = np.clip(t2, -1.0, 1.0)
    pitch = np.arcsin(t2)

    # yaw (zè½´æ—‹è½¬)
    t3 = 2.0 * (w * z + x * y)
    t4 = 1.0 - 2.0 * (y * y + z * z)
    yaw = np.arctan2(t3, t4)

    if degrees:
        factor = 180.0 / np.pi
        return roll * factor, pitch * factor, yaw * factor
    return roll, pitch, yaw

def read_filtered_frame_ranges(xlsx_path: str, num_actions_chunk: int= 8) -> List[Dict[str, Any]]:
    """è¯»å– filtered_frame_ranges.xlsxï¼Œè¿”å›æ¯è¡Œçš„å­—å…¸åˆ—è¡¨ã€‚

    æœŸæœ›åˆ—åï¼šset_id, episode_id, start_frame, end_frameã€‚
    """
    if not os.path.exists(xlsx_path):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°æ–‡ä»¶: {xlsx_path}")

    df = pd.read_excel(xlsx_path)
    # è§„èŒƒåˆ—å
    expected_cols = ["set_id", "episode_id", "start_frame", "end_frame"]
    missing_cols = [c for c in expected_cols if c not in df.columns]
    if missing_cols:
        raise ValueError(f"Excelç¼ºå°‘åˆ—: {missing_cols}; å®é™…åˆ—: {list(df.columns)}")

    records: List[Dict[str, Any]] = []
    for _, row in df.iterrows():
        try:
            set_id = str(row["set_id"]).strip()
            episode_id = int(row["episode_id"]) if not pd.isna(row["episode_id"]) else None
            start_frame = int(row["start_frame"]) if not pd.isna(row["start_frame"]) else 0
            end_frame = int(row["end_frame"]) if not pd.isna(row["end_frame"]) else -1
        except Exception as e:
            raise ValueError(f"è§£æè¡Œå¤±è´¥: {row.to_dict()} é”™è¯¯: {e}")

        if episode_id is None or end_frame < 0:
            continue
        
        for frame_idx in range(start_frame, end_frame-num_actions_chunk+1):
            records.append(
                {
                    "set_id": set_id,
                    "episode_id": episode_id,
                    "frame_idx": frame_idx,
                }
            )

    return records


if __name__ == "__main__":
    # print(quaternion_to_rpy([ 0.52416398, -0.22196564,  0.79680929,  0.20267791]))
    dataset = RobotDatasetReader("/mnt/data2/datasets/Real-robot/AgibotWorld-Alpha", "olmo/data/vla/agibot/agibot_alpha_frame_ranges.xlsx","olmo/data/vla/agibot/norm_stats.json",1)
    # print(len(dataset))
    # # ç¤ºä¾‹ï¼šä» Excel è¯»å–å¸§åŒºé—´å¹¶éå†å‰å‡ æ¡
    
    try:
        states = []
        from tqdm import tqdm
        for i,frame in enumerate(tqdm(dataset)):
            # assert frame["state"].shape == (14,), f"state shape: {frame['state'].shape}"
            print(frame["state"])
            print(frame["action"])
            # break
        #     if frame["state"].shape == (14,):
        #         states.append(frame["state"])
        #     # if i > 1000:
        #     #     break
        # # æ‹¼æ¥æˆä¸€ä¸ªæ•°ç»„
        # states = np.stack(states, axis=0)
        # actions = states
        # # ç»Ÿè®¡mean,std,max,min,q01,q99å¹¶å†™å…¥norm_stats.json
        # norm_stats = {
        #     "states": {
        #         "mean": states.mean(0).tolist(),
        #         "std": states.std(0).tolist(),
        #         "max": states.max(0).tolist(),
        #         "min": states.min(0).tolist(),
        #         "q01": np.quantile(states, 0.01, axis=0).tolist(),
        #         "q99": np.quantile(states, 0.99, axis=0).tolist(),
        #     },
        #     "actions": {
        #         "mean": actions.mean(0).tolist(),
        #         "std": actions.std(0).tolist(),
        #         "max": actions.max(0).tolist(),
        #         "min": actions.min(0).tolist(),
        #         "q01": np.quantile(actions, 0.01, axis=0).tolist(),
        #         "q99": np.quantile(actions, 0.99, axis=0).tolist(),
        #     },
        # }
        # with open("norm_stats.json", "w") as f:
        #     json.dump(norm_stats, f)
        # print(states.shape)
        # print(actions.shape)
    except Exception as e:
        # æ‰“å°å®Œæ•´é”™è¯¯ä¿¡æ¯
        import traceback
        print(f"å®Œæ•´é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        print(f"è¯»å–æˆ–è¿­ä»£å¤±è´¥: {e}")
